{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mille-s/GEM24_EvalLLM/blob/main/GEM24_EvalLLM_aiXplain_SM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Install Aixplain\n",
        "from IPython.display import clear_output\n",
        "! pip install aixplain\n",
        "clear_output()"
      ],
      "metadata": {
        "id": "BWaHAvGj8gCb",
        "collapsed": true,
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Download and Load human-eval-packaged json, and format contents (triples, text, id)\n",
        "import json\n",
        "import codecs\n",
        "from bs4 import BeautifulSoup\n",
        "import os\n",
        "\n",
        "\n",
        "language = \"Spanish\" #@param[\"English\", \"Spanish\", \"Swahili\"]\n",
        "data = 'regular' #@param[\"regular\", \"iaa\"]\n",
        "\n",
        "def format_json(json_path):\n",
        "  # Open en_regular and parse json\n",
        "  en_regular_json = json.load(codecs.open(json_path, 'r', 'utf-8'))\n",
        "  # Print first entry\n",
        "  # print(json.dumps(en_regular_json[0], indent=4))\n",
        "\n",
        "  triples_text_pairs = []\n",
        "\n",
        "  x = 0\n",
        "  while x < len(en_regular_json):\n",
        "    # if x < 10:\n",
        "    # Parse html found in the \"input\" key\n",
        "    html = en_regular_json[x]['input']\n",
        "    soup = BeautifulSoup(html, 'html.parser')\n",
        "    # Print raw table\n",
        "    # print(soup.prettify())\n",
        "    table = soup.find('table')\n",
        "    # headers = [header.text.strip() for header in table.find_all('th')]\n",
        "    rows = []\n",
        "    for row in table.find_all('tr'):\n",
        "      columns = row.find_all(['td', 'th'])  # Get both <td> and <th>\n",
        "      row_data = ' '.join([col.text.strip() for col in columns])\n",
        "      rows.append(row_data)\n",
        "    triples_formatted = '; '.join(rows[1:]) # exclude header\n",
        "    # print(\"Headers:\", rows[0])\n",
        "    # print(rows[1:])\n",
        "    triples_text_pairs.append({'id':en_regular_json[x]['id'], 'triples': '\"\"\"'+triples_formatted+'\"\"\"', 'text': en_regular_json[x]['output']})\n",
        "    # else:\n",
        "    #   break\n",
        "    x += 1\n",
        "  return triples_text_pairs\n",
        "\n",
        "if language == \"English\":\n",
        "  if data == 'regular':\n",
        "    if not os.path.exists('en_regular.json'):\n",
        "      ! gdown 1hOp1_zN2IgGeTnmzngOgIdLRXErchkEo\n",
        "    triples_text_pairs = format_json('en_regular.json')\n",
        "  elif data == 'iaa':\n",
        "    if not os.path.exists('en_iaa.json'):\n",
        "      ! gdown 1Q69osoEzJJBVqYH9t2ArPAaPAHVPNax5\n",
        "    triples_text_pairs = format_json('en_iaa.json')\n",
        "\n",
        "elif language == \"Spanish\":\n",
        "  if data == 'regular':\n",
        "    if not os.path.exists('es_regular.json'):\n",
        "      ! gdown 14hNTAfMqQI2-K81O9GZ4GkoybI2iO-sh\n",
        "    triples_text_pairs = format_json('es_regular.json')\n",
        "  elif data == 'iaa':\n",
        "    if not os.path.exists('es_iaa.json'):\n",
        "      ! gdown 1HadgIdWzcb7NTJYELKB-MJ-qa510e3M4\n",
        "    triples_text_pairs = format_json('es_iaa.json')\n",
        "\n",
        "elif language == \"Swahili\":\n",
        "  if data == 'regular':\n",
        "    if not os.path.exists('sw_regular.json'):\n",
        "      ! gdown 1Knp231CEdUQ-SDnJ_oknJDm2dogetSFg\n",
        "    triples_text_pairs = format_json('sw_regular.json')\n",
        "  elif data == 'iaa':\n",
        "    if not os.path.exists('sw_iaa.json'):\n",
        "      ! gdown 16JFZg8DacuhRvIAUJ0iMVqnvh4nrxZTX\n",
        "    triples_text_pairs = format_json('sw_iaa.json')"
      ],
      "metadata": {
        "cellView": "form",
        "id": "fKegUHmi3u52"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Print sample datapoint\n",
        "expected = 0\n",
        "if language == \"English\":\n",
        "  if data == 'regular':\n",
        "    expected = 8280\n",
        "    print('Expected: 8280')\n",
        "  elif data == 'iaa':\n",
        "    expected = 92\n",
        "    print('Expected: 92')\n",
        "elif language == \"Spanish\":\n",
        "  if data == 'regular':\n",
        "    expected = 3240\n",
        "    print('Expected: 3240')\n",
        "  elif data == 'iaa':\n",
        "    expected = 72\n",
        "    print('Expected: 72')\n",
        "elif language == \"Swahili\":\n",
        "  if data == 'regular':\n",
        "    expected = 2700\n",
        "    print('Expected: 2700')\n",
        "  elif data == 'iaa':\n",
        "    expected = 60\n",
        "    print('Expected: 60')\n",
        "print(f'Found: {len(triples_text_pairs)}')\n",
        "\n",
        "if not len(triples_text_pairs) == expected:\n",
        "  print('--------------------------------------------------\\n!!! ERROR: mismatch expected/found data points !!!\\n--------------------------------------------------')\n",
        "\n",
        "print(triples_text_pairs[0])\n",
        "\n",
        "# Triples = '\"\"\"Marcus_Aurelius HasChild Fadilla; Marcus_Aurelius StudentOf Alexander_of_Cotiaeum; Marcus_Aurelius Spouse Faustina_the_Younger; Marcus_Aurelius PositionHeld Roman_emperor\"\"\"'\n",
        "# Nice_Text = '''Marcus Aurelius was a student of Alexander of Cotiaeum and had a child named Fadilla. He was married to Faustina the Younger. He was a Roman emperor and died in Vindobona.'''"
      ],
      "metadata": {
        "id": "cxg80KZZCNyY",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ofwSLwpTyK9U",
        "collapsed": true,
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Run evaluation (needs aiXplain API key in Parameters)\n",
        "import os\n",
        "import json\n",
        "import csv\n",
        "import pickle\n",
        "\n",
        "# PARAMETERS aiXplain\n",
        "#==========================\n",
        "os.environ[\"AIXPLAIN_API_KEY\"] = 'INSERT_KEY_HERE'\n",
        "Gemini_1dot5_Flash = '674b73f06eb563a748561d41' # Code double checked\n",
        "path_out = 'Gemini_results'\n",
        "#==========================\n",
        "from aixplain.factories import AgentFactory\n",
        "# from aixplain.modules.agent import ModelTool\n",
        "from aixplain.modules.agent.tool.model_tool import ModelTool\n",
        "\n",
        "if not os.path.exists(path_out):\n",
        "  os.makedirs(path_out)\n",
        "\n",
        "def dumpResults(annotations, path_out):\n",
        "  results_file = open(os.path.join(path_out, 'All_Gemini_results'), 'ab')\n",
        "  pickle.dump(annotations, results_file)\n",
        "  results_file.close()\n",
        "\n",
        "def callGemini_aiXplain(prompt, model):\n",
        "  agent = AgentFactory.create(\n",
        "    name=\"Assessment of text quality\",\n",
        "\t  description=\"Assessment of text quality\",\n",
        "\t  instructions=\"\",\n",
        "    tools=[\n",
        "      ModelTool(model=model),\n",
        "    ],\n",
        "  )\n",
        "  agent_response = agent.run(prompt)\n",
        "\n",
        "  return agent_response\n",
        "\n",
        "def runEval(triples_text_pairs, model):\n",
        "  # EN regular splits: range(0, 2750), range(2750, 5500), range(5500, 8280)\n",
        "  x = 0\n",
        "  # To get all evaluations\n",
        "  for x in range(0, len(triples_text_pairs)):\n",
        "  # for x in range(7413, 8280):\n",
        "  # while x < 3:\n",
        "    Triples = triples_text_pairs[x]['triples']\n",
        "    Nice_Text = triples_text_pairs[x]['text']\n",
        "    id = triples_text_pairs[x]['id']\n",
        "\n",
        "    #Prompt (Do not change unless discussed with the GEM-HumEval group)\n",
        "    prompt = '''\n",
        "In this task, you will evaluate the quality of the Text in relation to the given Triple Set. How well does the Text represent the Triple Set?  You will be given four specific Dimensions to evaluate against:\n",
        "\n",
        "Dimensions:\"\"\"\n",
        "No-Omissions: ALL the information in the Triple Set is present in the Text.\n",
        "No-Additions: ONLY information from the Triple Set is present in the Text.\n",
        "Grammaticality: The Text is free of grammatical and spelling errors.\n",
        "Fluency: The Text flows well and is easy to read; its parts are connected in a natural way.\"\"\"\n",
        "\n",
        "Important note on No-Omissions and No-Additions: some Triple Set/Text pairs contain non-factual information and even fictional names for people, places, dates, etc. Whether there are omissions and/or additions in a Text is NOT related to factual truth, but instead is strictly related to the contents of the input Triple Set.\n",
        "Important note on Grammaticality and Fluency: for Grammaticality and Fluency you do not need to consider the input Triple Set; only the intrinsic quality of the Text needs to be assessed.\n",
        "\n",
        "You need to provide the scores ranging from 1 (indicating the lowest score) to 7 (indicating the highest score) for each of the dimensions and a short justification for each score in the following JSON format:  {\"No-Omissions\": {\"Justification\": \"\", \"Score\": \"\"}, \"No-Additions\": {\"Justification\": \"\", \"Score\": \"\"}, \"Grammaticality\": {\"Justification\": \"\", \"Score\": \"\"}, \"Fluency\": {\"Justification\": \"\", \"Score\": \"\"} }.\n",
        "\n",
        "Make sure to read thoroughly the Triple Set and the '''+str(language)+''' Text below, and assess the four Dimensions using the instructions and template above.\n",
        "\n",
        "Triple Set: ''' + str(Triples) + \"\\n\" + '''Text: '''+ str(Nice_Text) + \"\\n\\n\" + '''\n",
        "'''\n",
        "    print(f'Evaluating text #{x}...')\n",
        "\n",
        "    # To run missing evals\n",
        "    # if id == 'en_D2T-1-FA_1318_6' or id == 'en_D2T-1-FA_0342_6':\n",
        "    # if id == 'es_D2T-1-FA_0614_2':\n",
        "    # Begin indent block\n",
        "    responseGemini = callGemini_aiXplain(prompt, model)\n",
        "    # Gemini does not always output correct json format, so I save the raw result at this point\n",
        "    triples_text_pairs[x]['scores_Gemini'] = str(responseGemini['data']['output'])\n",
        "\n",
        "    # Save individual files as backup\n",
        "    with open(os.path.join('Gemini_results', 'Gemini_results_'+str(id)), 'ab') as f:\n",
        "      pickle.dump(triples_text_pairs[x], f)\n",
        "    # End indent block\n",
        "\n",
        "    x += 1\n",
        "\n",
        "  return triples_text_pairs\n",
        "\n",
        "annotations = runEval(triples_text_pairs, Gemini_1dot5_Flash)\n",
        "\n",
        "# dumpResults(annotations, path_out)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Zip and download Gemini_results folder\n",
        "from google.colab import files\n",
        "import datetime\n",
        "\n",
        "date = datetime.date.today().strftime(\"%y%m%d\")\n",
        "zip_name = f'{date}_{language}_GeminiFlash1dot5_{data}_{str(len(triples_text_pairs))}.zip'\n",
        "# zip_name = f'{date}_{language}_{model}_{data}_0001-2750.zip'\n",
        "\n",
        "!zip -r /content/{zip_name} /content/Gemini_results\n",
        "files.download(zip_name)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "qv63xq_QO_6d",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Results analysis"
      ],
      "metadata": {
        "id": "twtHvjIruiSm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Unzip uploaded file\n",
        "import os\n",
        "import zipfile\n",
        "from IPython.display import clear_output\n",
        "\n",
        "# !unzip /content/GPT_results.zip -d /content\n",
        "zip_language = 'ES' #@param['EN', 'ES', 'SW']\n",
        "zip_model = 'Gemini-1dot5-flash' #@param['GPT-4o-mini', 'GPT-o3-mini', 'Gemini-1dot5-flash']\n",
        "zip_data = 'regular' #@param['regular', 'iaa']\n",
        "\n",
        "def unzipEvals(path_dir, zip_path):\n",
        "  if os.path.exists(path_dir):\n",
        "    # Remove folder contents\n",
        "    for filename in os.listdir(path_dir):\n",
        "      file_path = os.path.join(path_dir, filename)\n",
        "  else:\n",
        "    os.makedirs(path_dir)\n",
        "  ! unzip {zip_path} -d {path_dir}\n",
        "\n",
        "path_dir = os.path.join(zip_language+'_'+zip_data, zip_model)\n",
        "zip_path = ''\n",
        "if zip_data == 'regular':\n",
        "  if zip_model == 'GPT-4o-mini':\n",
        "    if zip_language == 'EN':\n",
        "      zip_path = '/content/250207_English_gpt-4o-mini-2024-07-18_regular_8280.zip'\n",
        "    elif zip_language == 'ES':\n",
        "      zip_path = '/content/250211_Spanish_gpt-4o-mini-2024-07-18_regular_3240.zip'\n",
        "    elif zip_language == 'SW':\n",
        "      zip_path = '/content/250211_Swahili_gpt-4o-mini-2024-07-18_regular_2700.zip'\n",
        "  elif zip_model == 'GPT-o3-mini':\n",
        "    if zip_language == 'EN':\n",
        "      zip_path = '/content/250213_English_o3-mini-2025-01-31_regular_8280.zip'\n",
        "    elif zip_language == 'ES':\n",
        "      zip_path = '/content/250212_Spanish_o3-mini-2025-01-31_regular_3240.zip'\n",
        "    elif zip_language == 'SW':\n",
        "      zip_path = '/content/250214_Swahili_o3-mini-2025-01-31_regular_2700.zip'\n",
        "  elif zip_model == 'Gemini-1dot5-flash':\n",
        "    if zip_language == 'EN':\n",
        "      zip_path = '/content/250227_English_GeminiFlash1dot5_regular_8280.zip'\n",
        "    elif zip_language == 'ES':\n",
        "      zip_path = '/content/250225_Spanish_GeminiFlash1dot5_regular_3240.zip'\n",
        "    elif zip_language == 'SW':\n",
        "     zip_path = '/content/250225_Swahili_GeminiFlash1dot5_regular_2700.zip'\n",
        "\n",
        "unzipEvals(path_dir, zip_path)\n",
        "\n",
        "clear_output()"
      ],
      "metadata": {
        "id": "ajyFBxlFPWaD",
        "cellView": "form",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Load unzipped files\n",
        "import pickle\n",
        "import glob\n",
        "import json\n",
        "import re\n",
        "import codecs\n",
        "\n",
        "update_params_unzip = False #@param {type:\"boolean\"}\n",
        "if update_params_unzip:\n",
        "  zip_language = 'ES' #@param['EN', 'ES', 'SW']\n",
        "  zip_model = 'Gemini-1dot5-flash' #@param['GPT-4o-mini', 'GPT-o3-mini', 'Gemini-1dot5-flash']\n",
        "  zip_data = 'regular' #@param['regular', 'iaa']\n",
        "\n",
        "model_scores = [1, 2, 3, 4, 5, 6, 7]\n",
        "# load_gemini_folder = True #@param {type:\"boolean\"}\n",
        "# load_gpt_folder = False #@param {type:\"boolean\"}\n",
        "path_dir_unzipped = ''\n",
        "model_prefix = ''\n",
        "if zip_model.startswith('Gemini'):\n",
        "  path_dir_unzipped = os.path.join('/content', zip_language+'_'+zip_data, zip_model, 'content', 'Gemini_results')\n",
        "  model_prefix = 'Gemini'\n",
        "elif zip_model.startswith('GPT'):\n",
        "  path_dir_unzipped = os.path.join('/content', zip_language+'_'+zip_data, zip_model, 'content', 'GPT_results')\n",
        "  model_prefix = 'GPT'\n",
        "\n",
        "def separateJustification(LLMoutString, criterion):\n",
        "  \"\"\"\n",
        "  The Justifications returned by the models often break the json format, so I extract them\n",
        "  \"\"\"\n",
        "  search_expression = '(\"'+criterion+'\":[^\\{]+\\{[^\\}]*\"Justification\":)([^\\}]+)(\"Score\":[^\\}]+\\})'\n",
        "  if re.search(search_expression, LLMoutString):\n",
        "    justificationRemoved = re.sub(search_expression, '\\g<1> \"\", \\g<3>',  LLMoutString)\n",
        "    justification = re.sub('^.*'+search_expression+'.*$', '\\g<2>',  LLMoutString)\n",
        "  else:\n",
        "    justificationRemoved = LLMoutString\n",
        "    justification = ''\n",
        "  return justificationRemoved, justification\n",
        "\n",
        "def loadDataPoint(dbfile_x, model):\n",
        "  eval_missing = None\n",
        "  wrong_score = None\n",
        "  dico_key = 'scores_'+str(model)\n",
        "  formatted_scores = {}\n",
        "  # load data with pickle\n",
        "  dp = pickle.load(dbfile_x)\n",
        "  if dico_key in dp:\n",
        "    print(dp['id'])\n",
        "    print(dp['triples'])\n",
        "    print(dp['text'])\n",
        "    justifications = []\n",
        "    # pickle.load uses single quotes, whereas json.load expects double quotes\n",
        "    # Gemini adds a node \"query\" in the json, unlike OpenAI's models\n",
        "    LLMout_string = str(dp[dico_key]).replace(\"'query'\", '\"query\"')\n",
        "    LLMout_string = LLMout_string.replace(\"```json\", \"\")\n",
        "    LLMout_string = LLMout_string.replace(\"```\", \"\")\n",
        "    LLMout_string = LLMout_string.replace(\"'No-Omissions'\", '\"No-Omissions\"')\n",
        "    # There's a typo in one of the Gemini outputs\n",
        "    LLMout_string = LLMout_string.replace(\"'No-Omissons'\", '\"No-Omissions\"')\n",
        "    LLMout_string = LLMout_string.replace('\"No-Omissons\"', '\"No-Omissions\"')\n",
        "    LLMout_string = LLMout_string.replace(\"'No-Additions'\", '\"No-Additions\"')\n",
        "    LLMout_string = LLMout_string.replace(\"'Grammaticality'\", '\"Grammaticality\"')\n",
        "    LLMout_string = LLMout_string.replace(\"'Fluency'\", '\"Fluency\"')\n",
        "    # Sometimes justifications are followed by single quotes, sometimes by double quotes\n",
        "    LLMout_string = LLMout_string.replace(\"'Justification': '\", '\"Justification\": \"').replace(\"'Justification'\", '\"Justification\"')\n",
        "    LLMout_string = LLMout_string.replace(\"', 'Score'\", '\", \"Score\"').replace(\"'Score'\", '\"Score\"')\n",
        "    if LLMout_string == 'None':\n",
        "      eval_missing = dp['id']\n",
        "    else:\n",
        "      # print(LLMout_string)\n",
        "      # LLMout_string = re.sub('(\"No-Omissions\":[^\\{]+\\{\"Justification\":)([^\\}]+)(\"Score\":[^\\}]+\\})', '\\g<1> \"\", \\g<3>',  LLMout_string)\n",
        "      LLMout_string, justifNoOm = separateJustification(LLMout_string, 'No-Omissions')\n",
        "      justifications.append(justifNoOm)\n",
        "      LLMout_string, justifNoAdd = separateJustification(LLMout_string, 'No-Additions')\n",
        "      justifications.append(justifNoAdd)\n",
        "      LLMout_string, justifGram = separateJustification(LLMout_string, 'Grammaticality')\n",
        "      justifications.append(justifGram)\n",
        "      LLMout_string, justifFlu = separateJustification(LLMout_string, 'Fluency')\n",
        "      justifications.append(justifFlu)\n",
        "      print(justifications)\n",
        "      LLMout_string = LLMout_string.replace(\"'1'\", '\"1\"')\n",
        "      LLMout_string = LLMout_string.replace(\"'2'\", '\"2\"')\n",
        "      LLMout_string = LLMout_string.replace(\"'3'\", '\"3\"')\n",
        "      LLMout_string = LLMout_string.replace(\"'4'\", '\"4\"')\n",
        "      LLMout_string = LLMout_string.replace(\"'5'\", '\"5\"')\n",
        "      LLMout_string = LLMout_string.replace(\"'6'\", '\"6\"')\n",
        "      LLMout_string = LLMout_string.replace(\"'7'\", '\"7\"')\n",
        "      scores_json = json.loads(LLMout_string)\n",
        "      clean_scores_json = None\n",
        "      # Gemini adds a node \"query\" in the json, unlike OpenAI's models\n",
        "      if 'query' in scores_json:\n",
        "        clean_scores_json = scores_json['query']\n",
        "      else:\n",
        "        clean_scores_json = scores_json\n",
        "\n",
        "      gram_score = int(clean_scores_json['Grammaticality']['Score'])\n",
        "      flu_score = int(clean_scores_json['Fluency']['Score'])\n",
        "      no_om_score = int(clean_scores_json['No-Omissions']['Score'])\n",
        "      no_ad_score = int(clean_scores_json['No-Additions']['Score'])\n",
        "\n",
        "      if (gram_score not in model_scores) or (flu_score not in model_scores) or (no_om_score not in model_scores) or (no_ad_score not in model_scores):\n",
        "        wrong_score = dp['id']\n",
        "\n",
        "      formatted_scores[\"eid\"] = dp['id']\n",
        "      formatted_scores[\"annotator_id\"] = str(zip_model)\n",
        "      formatted_scores[\"no-omissions\"] = no_om_score\n",
        "      formatted_scores[\"no-additions\"] = no_ad_score\n",
        "      formatted_scores[\"grammaticality\"] = gram_score\n",
        "      formatted_scores[\"fluency\"] = flu_score\n",
        "\n",
        "      print(f\"Gram: {gram_score}; Flu: {flu_score}; NoOm: {no_om_score}; NoAd: {no_ad_score}.\")\n",
        "      print('')\n",
        "\n",
        "  return formatted_scores, eval_missing, wrong_score\n",
        "\n",
        "print(path_dir_unzipped)\n",
        "print(model_prefix)\n",
        "eval_files = glob.glob(os.path.join(path_dir_unzipped, '*'))\n",
        "evals_missing = []\n",
        "wrong_scores = []\n",
        "all_scores = []\n",
        "for filepath in eval_files:\n",
        "  print(filepath)\n",
        "  dbfile_x = open(filepath, 'rb')\n",
        "  formatted_scores, eval_missing, wrong_score = loadDataPoint(dbfile_x, model_prefix)\n",
        "  if eval_missing != None:\n",
        "    evals_missing.append(eval_missing)\n",
        "  if wrong_score != None:\n",
        "    wrong_scores.append(wrong_score)\n",
        "  dbfile_x.close()\n",
        "  all_scores.append(formatted_scores)\n",
        "print(f'Missing evaluations: {evals_missing}')\n",
        "print(f'Wrong scores: {wrong_scores}')\n",
        "\n",
        "# Save all scores into a json file\n",
        "path_json_out = zip_language+'_'+zip_model+'_scores.json'\n",
        "with codecs.open(path_json_out, 'w', 'utf-8') as outfile:\n",
        "  json.dump(all_scores, outfile)"
      ],
      "metadata": {
        "id": "cQDPBbTqIVOW",
        "collapsed": true,
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}